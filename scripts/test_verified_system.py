#!/usr/bin/env python3
"""
Test Script for Verified Persian Legal AI System
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªØ³Øª Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø­Ù‚ÙˆÙ‚ÛŒ ÙØ§Ø±Ø³ÛŒ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯Ù‡

Tests the verified dataset integration system without requiring external dependencies.
"""

import sys
import os
import logging
from pathlib import Path

# Add backend to path for imports
sys.path.append(str(Path(__file__).parent.parent / "backend"))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_imports():
    """Test that all modules can be imported"""
    try:
        logger.info("ğŸ” Testing module imports...")
        
        # Test dataset integrator
        from data.dataset_integrator import PersianLegalDataIntegrator
        logger.info("âœ… PersianLegalDataIntegrator imported successfully")
        
        # Test quality validator
        from validation.dataset_validator import DatasetQualityValidator
        logger.info("âœ… DatasetQualityValidator imported successfully")
        
        # Test verified trainer
        from models.verified_data_trainer import VerifiedDataTrainer
        logger.info("âœ… VerifiedDataTrainer imported successfully")
        
        return True
        
    except ImportError as e:
        logger.error(f"âŒ Import failed: {e}")
        return False

def test_initialization():
    """Test that all components can be initialized"""
    try:
        logger.info("ğŸ”§ Testing component initialization...")
        
        # Test dataset integrator initialization
        integrator = PersianLegalDataIntegrator()
        logger.info("âœ… PersianLegalDataIntegrator initialized")
        
        # Test quality validator initialization
        validator = DatasetQualityValidator()
        logger.info("âœ… DatasetQualityValidator initialized")
        
        # Test verified trainer initialization
        trainer = VerifiedDataTrainer()
        logger.info("âœ… VerifiedDataTrainer initialized")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Initialization failed: {e}")
        return False

def test_api_compatibility():
    """Test that API endpoints maintain compatibility"""
    try:
        logger.info("ğŸŒ Testing API compatibility...")
        
        # Test that training endpoints can be imported
        from api.training_endpoints import router, verified_trainer
        logger.info("âœ… Training endpoints imported successfully")
        
        # Test that verified trainer is available
        if verified_trainer is not None:
            logger.info("âœ… Verified trainer available in API")
        else:
            logger.warning("âš ï¸ Verified trainer not available in API")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ API compatibility test failed: {e}")
        return False

def test_typescript_compatibility():
    """Test that TypeScript interfaces are preserved"""
    try:
        logger.info("ğŸ“ Testing TypeScript compatibility...")
        
        # Check that TypeScript files exist and are unchanged
        typescript_files = [
            "frontend/src/types/realData.ts",
            "frontend/src/api/persian-ai-api.js"
        ]
        
        for file_path in typescript_files:
            if os.path.exists(file_path):
                logger.info(f"âœ… TypeScript file exists: {file_path}")
            else:
                logger.warning(f"âš ï¸ TypeScript file not found: {file_path}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ TypeScript compatibility test failed: {e}")
        return False

def test_verified_datasets_config():
    """Test verified datasets configuration"""
    try:
        logger.info("ğŸ“Š Testing verified datasets configuration...")
        
        from data.dataset_integrator import PersianLegalDataIntegrator
        
        integrator = PersianLegalDataIntegrator()
        datasets = integrator.VERIFIED_DATASETS
        
        logger.info(f"âœ… Found {len(datasets)} verified datasets:")
        for key, config in datasets.items():
            logger.info(f"  - {config['name']}: {config['hf_path']}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Verified datasets test failed: {e}")
        return False

def test_validation_logic():
    """Test validation logic without external dependencies"""
    try:
        logger.info("ğŸ” Testing validation logic...")
        
        from validation.dataset_validator import DatasetQualityValidator
        
        validator = DatasetQualityValidator()
        
        # Test Persian character detection
        persian_text = "Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª"
        persian_chars = set('Ø§Ø¨Ù¾ØªØ«Ø¬Ú†Ø­Ø®Ø¯Ø°Ø±Ø²Ú˜Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚Ú©Ú¯Ù„Ù…Ù†ÙˆÙ‡ÛŒ')
        persian_count = sum(1 for char in persian_text if char in persian_chars)
        
        if persian_count > 0:
            logger.info("âœ… Persian character detection working")
        else:
            logger.warning("âš ï¸ Persian character detection not working")
        
        # Test legal keyword detection
        legal_text = "Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ø¬Ø¯ÛŒØ¯ Ø§Ø³Øª Ùˆ Ø¯Ø± Ø¯Ø§Ø¯Ú¯Ø§Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯"
        legal_keywords = ['Ù‚Ø§Ù†ÙˆÙ†', 'Ø¯Ø§Ø¯Ú¯Ø§Ù‡', 'Ø­Ù‚ÙˆÙ‚']
        legal_count = sum(1 for keyword in legal_keywords if keyword in legal_text)
        
        if legal_count > 0:
            logger.info("âœ… Legal keyword detection working")
        else:
            logger.warning("âš ï¸ Legal keyword detection not working")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Validation logic test failed: {e}")
        return False

def main():
    """Main test function"""
    print("ğŸ§ª Persian Legal AI Verified System Test")
    print("=" * 50)
    
    tests = [
        ("Module Imports", test_imports),
        ("Component Initialization", test_initialization),
        ("API Compatibility", test_api_compatibility),
        ("TypeScript Compatibility", test_typescript_compatibility),
        ("Verified Datasets Config", test_verified_datasets_config),
        ("Validation Logic", test_validation_logic)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\nğŸ” Running {test_name} test...")
        try:
            result = test_func()
            results[test_name] = result
            status = "âœ… PASS" if result else "âŒ FAIL"
            print(f"{status} - {test_name}")
        except Exception as e:
            results[test_name] = False
            print(f"âŒ FAIL - {test_name}: {e}")
    
    # Summary
    print("\n" + "=" * 50)
    print("ğŸ“Š Test Results Summary:")
    
    passed = sum(1 for result in results.values() if result)
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} - {test_name}")
    
    print(f"\nOverall: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ All tests passed! System is ready for verified dataset integration.")
        return 0
    else:
        print("âš ï¸ Some tests failed. Please check the logs for details.")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)