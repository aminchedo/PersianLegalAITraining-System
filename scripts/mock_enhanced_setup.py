#!/usr/bin/env python3
"""
Mock Enhanced Persian BERT Setup (For Testing Without Heavy Dependencies)
========================================================================
Creates mock Persian BERT setup for testing integration without downloading large models
"""

import os
import sys
import json
import subprocess
from pathlib import Path
import time

class MockEnhancedModelSetup:
    """Mock enhanced model setup for testing purposes"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.models_dir = self.project_root / "ai_models"
        self.cache_dir = self.models_dir / "cache"
        self.enhanced_dir = self.models_dir / "enhanced"
        
        # Create directories safely
        for directory in [self.models_dir, self.cache_dir, self.enhanced_dir]:
            directory.mkdir(parents=True, exist_ok=True)
        
        print(f"Mock enhanced setup initialized - Models dir: {self.models_dir}")
    
    def check_existing_setup(self) -> dict:
        """Check what's already working"""
        status = {
            "existing_models": [],
            "existing_data": [],
            "existing_scripts": []
        }
        
        # Check existing models
        if self.cache_dir.exists():
            existing_models = list(self.cache_dir.iterdir())
            status["existing_models"] = [m.name for m in existing_models if m.is_dir()]
        
        # Check existing datasets
        datasets_dir = self.models_dir / "datasets"
        if datasets_dir.exists():
            existing_data = list(datasets_dir.glob("*.json"))
            status["existing_data"] = [d.name for d in existing_data]
        
        print(f"âœ… Found existing models: {status['existing_models']}")
        print(f"âœ… Found existing data: {status['existing_data']}")
        
        return status
    
    def mock_install_dependencies(self) -> bool:
        """Mock dependency installation for testing"""
        print("ğŸ“¦ Mock dependency check (no actual installation)...")
        
        # Simulate dependency check without actually installing
        required_packages = ['torch', 'transformers', 'huggingface_hub']
        
        print("âœ… Mock dependencies satisfied for testing")
        return True
    
    def create_mock_persian_bert(self) -> bool:
        """Create mock Persian BERT structure for testing"""
        bert_path = self.enhanced_dir / "persian_bert"
        
        if bert_path.exists():
            print(f"âœ… Mock Persian BERT already exists at: {bert_path}")
            return True
        
        print("ğŸ“¥ Creating mock Persian BERT structure...")
        
        try:
            # Create mock model directory structure
            bert_path.mkdir(exist_ok=True)
            
            # Create mock config file
            mock_config = {
                "model_type": "bert",
                "vocab_size": 50000,
                "hidden_size": 768,
                "num_hidden_layers": 12,
                "num_attention_heads": 12,
                "intermediate_size": 3072,
                "hidden_act": "gelu",
                "hidden_dropout_prob": 0.1,
                "attention_probs_dropout_prob": 0.1,
                "max_position_embeddings": 512,
                "type_vocab_size": 2,
                "initializer_range": 0.02,
                "layer_norm_eps": 1e-12,
                "pad_token_id": 0,
                "position_embedding_type": "absolute",
                "use_cache": True,
                "classifier_dropout": None,
                "architectures": ["BertModel"],
                "model_name": "HooshvareLab/bert-base-parsbert-uncased"
            }
            
            with open(bert_path / "config.json", "w") as f:
                json.dump(mock_config, f, indent=2)
            
            # Create mock tokenizer files
            mock_tokenizer_config = {
                "do_lower_case": True,
                "do_basic_tokenize": True,
                "never_split": None,
                "unk_token": "[UNK]",
                "sep_token": "[SEP]",
                "pad_token": "[PAD]",
                "cls_token": "[CLS]",
                "mask_token": "[MASK]",
                "tokenize_chinese_chars": True,
                "strip_accents": None,
                "model_max_length": 512,
                "special_tokens_map_file": None,
                "name_or_path": "HooshvareLab/bert-base-parsbert-uncased",
                "tokenizer_class": "BertTokenizer"
            }
            
            with open(bert_path / "tokenizer_config.json", "w") as f:
                json.dump(mock_tokenizer_config, f, indent=2)
            
            # Create mock vocab file (simplified)
            mock_vocab = {
                "[PAD]": 0,
                "[UNK]": 1,
                "[CLS]": 2,
                "[SEP]": 3,
                "[MASK]": 4,
                "Ùˆ": 5,
                "Ø¯Ø±": 6,
                "Ø¨Ù‡": 7,
                "Ø§Ø²": 8,
                "Ú©Ù‡": 9,
                "Ø§ÛŒÙ†": 10,
                "Ø¨Ø±Ø§ÛŒ": 11,
                "Ø¨Ø§": 12,
                "Ø§Ø³Øª": 13,
                "Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯": 14,
                "Ø¯Ø§Ø¯Ú¯Ø§Ù‡": 15,
                "Ø´Ú©Ø§ÛŒØª": 16,
                "ÙˆÚ©Ø§Ù„Øª": 17,
                "Ù‚Ø§Ù†ÙˆÙ†": 18,
                "Ø­Ù‚ÙˆÙ‚": 19,
                "Ù…Ø¯Ù†ÛŒ": 20,
                "Ú©ÛŒÙØ±ÛŒ": 21
            }
            
            with open(bert_path / "vocab.txt", "w", encoding="utf-8") as f:
                for token, idx in sorted(mock_vocab.items(), key=lambda x: x[1]):
                    f.write(f"{token}\n")
            
            # Create mock model info
            model_info = {
                "model_name": "HooshvareLab/bert-base-parsbert-uncased",
                "local_path": str(bert_path),
                "vocab_size": len(mock_vocab),
                "verified_at": time.time(),
                "test_passed": True,
                "is_mock": True,
                "mock_created_at": time.time()
            }
            
            with open(bert_path.parent / "model_info.json", "w") as f:
                json.dump(model_info, f, indent=2)
            
            print("âœ… Mock Persian BERT structure created successfully")
            return True
            
        except Exception as e:
            print(f"âŒ Mock creation failed: {e}")
            return False
    
    def create_enhanced_sample_data(self) -> bool:
        """Create enhanced sample data without overwriting existing"""
        enhanced_datasets_dir = self.enhanced_dir / "datasets"
        enhanced_datasets_dir.mkdir(exist_ok=True)
        
        # Check if enhanced data already exists
        enhanced_docs_file = enhanced_datasets_dir / "enhanced_legal_documents.json"
        if enhanced_docs_file.exists():
            print("âœ… Enhanced sample data already exists")
            return True
        
        print("ğŸ“„ Creating enhanced Persian legal sample data...")
        
        enhanced_documents = {
            "documents": [
                {
                    "id": "enhanced_contract_001",
                    "title": "Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø®Ø±ÛŒØ¯ Ùˆ ÙØ±ÙˆØ´ Ù…Ù„Ú© - Ù†Ù…ÙˆÙ†Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡",
                    "content": """Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø®Ø±ÛŒØ¯ Ùˆ ÙØ±ÙˆØ´ Ù…Ù„Ú© Ù…Ø³Ú©ÙˆÙ†ÛŒ
                    
Ø§ÛŒÙ† Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø¯Ø± ØªØ§Ø±ÛŒØ® Û±Û´Û°Û²/Û±Û²/Û²Û° Ø¨ÛŒÙ†:
- Ø·Ø±Ù Ø§ÙˆÙ„: Ø¢Ù‚Ø§ÛŒ Ù…Ø­Ù…Ø¯ Ø±Ø¶Ø§ Ø§Ø­Ù…Ø¯ÛŒ ÙØ±Ø²Ù†Ø¯ Ø¹Ù„ÛŒØŒ Ú©Ø¯ Ù…Ù„ÛŒ: Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹Û° (ÙØ±ÙˆØ´Ù†Ø¯Ù‡)
- Ø·Ø±Ù Ø¯ÙˆÙ…: Ø®Ø§Ù†Ù… ÙØ§Ø·Ù…Ù‡ Ù…Ø­Ù…Ø¯ÛŒ ÙØ±Ø²Ù†Ø¯ Ø­Ø³Ù†ØŒ Ú©Ø¯ Ù…Ù„ÛŒ: Û°Û¹Û¸Û·Û¶ÛµÛ´Û³Û²Û± (Ø®Ø±ÛŒØ¯Ø§Ø±)

Ù…Ù†Ø¹Ù‚Ø¯ Ú¯Ø±Ø¯ÛŒØ¯.

Ù…Ø§Ø¯Ù‡ Û± - Ù…ÙˆØ¶ÙˆØ¹ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯:
ÙØ±ÙˆØ´Ù†Ø¯Ù‡ Ù…ØªØ¹Ù‡Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ù…Ù„Ú© Ù…Ø³Ú©ÙˆÙ†ÛŒ ÙˆØ§Ù‚Ø¹ Ø¯Ø± ØªÙ‡Ø±Ø§Ù†ØŒ Ù…Ù†Ø·Ù‚Ù‡ Û³ØŒ Ø®ÛŒØ§Ø¨Ø§Ù† ÙˆÙ„ÛŒØ¹ØµØ±ØŒ Ø®ÛŒØ§Ø¨Ø§Ù† ÙÙ„Ø³Ø·ÛŒÙ†ØŒ Ù¾Ù„Ø§Ú© Û±Û²ÛµØŒ Ø·Ø¨Ù‚Ù‡ Ø³ÙˆÙ…ØŒ ÙˆØ§Ø­Ø¯ Ø´Ù…Ø§Ø±Ù‡ Û¶ Ø±Ø§ Ø¨Ø§ Ù…Ø³Ø§Ø­Øª Û±Û²Û° Ù…ØªØ± Ù…Ø±Ø¨Ø¹ Ø¨Ù‡ Ø®Ø±ÛŒØ¯Ø§Ø± Ù…Ù†ØªÙ‚Ù„ Ù†Ù…Ø§ÛŒØ¯.

Ù…Ø§Ø¯Ù‡ Û² - Ù…Ø¨Ù„Øº Ùˆ Ù†Ø­ÙˆÙ‡ Ù¾Ø±Ø¯Ø§Ø®Øª:
Ù…Ø¨Ù„Øº Ú©Ù„ Ù…Ø¹Ø§Ù…Ù„Ù‡ Û±Û¸ØŒÛ°Û°Û°ØŒÛ°Û°Û°ØŒÛ°Û°Û° (Ù‡Ø¬Ø¯Ù‡ Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯) Ø±ÛŒØ§Ù„ Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡ Ø´Ø±Ø­ Ø²ÛŒØ± Ù¾Ø±Ø¯Ø§Ø®Øª Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯:
- Ù¾ÛŒØ´ Ù¾Ø±Ø¯Ø§Ø®Øª: ÛµØŒÛ°Û°Û°ØŒÛ°Û°Û°ØŒÛ°Û°Û° Ø±ÛŒØ§Ù„ Ù†Ù‚Ø¯
- Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: Û±Û³ØŒÛ°Û°Û°ØŒÛ°Û°Û°ØŒÛ°Û°Û° Ø±ÛŒØ§Ù„ Ø·ÛŒ Û¶ Ù‚Ø³Ø· Ù…Ø§Ù‡Ø§Ù†Ù‡

Ù…Ø§Ø¯Ù‡ Û³ - ØªØ­ÙˆÛŒÙ„ Ù…Ù„Ú©:
ØªØ­ÙˆÛŒÙ„ Ù…Ù„Ú© Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ§ ØªØ§Ø±ÛŒØ® Û±Û´Û°Û³/Û²/Û±Ûµ Ø§Ù†Ø¬Ø§Ù… Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.""",
                    "category": "Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯",
                    "subcategory": "Ø®Ø±ÛŒØ¯ Ùˆ ÙØ±ÙˆØ´ Ù…Ù„Ú©",
                    "legal_domain": "Ø­Ù‚ÙˆÙ‚ Ù…Ø¯Ù†ÛŒ",
                    "complexity": "Ù…ØªÙˆØ³Ø·",
                    "entities": {
                        "parties": ["Ù…Ø­Ù…Ø¯ Ø±Ø¶Ø§ Ø§Ø­Ù…Ø¯ÛŒ", "ÙØ§Ø·Ù…Ù‡ Ù…Ø­Ù…Ø¯ÛŒ"],
                        "amounts": ["Û±Û¸ØŒÛ°Û°Û°ØŒÛ°Û°Û°ØŒÛ°Û°Û° Ø±ÛŒØ§Ù„", "ÛµØŒÛ°Û°Û°ØŒÛ°Û°Û°ØŒÛ°Û°Û° Ø±ÛŒØ§Ù„"],
                        "dates": ["Û±Û´Û°Û²/Û±Û²/Û²Û°", "Û±Û´Û°Û³/Û²/Û±Ûµ"],
                        "locations": ["ØªÙ‡Ø±Ø§Ù†ØŒ Ù…Ù†Ø·Ù‚Ù‡ Û³ØŒ Ø®ÛŒØ§Ø¨Ø§Ù† ÙˆÙ„ÛŒØ¹ØµØ±"]
                    }
                },
                {
                    "id": "enhanced_judgment_001",
                    "title": "Ø¯Ø§Ø¯Ù†Ø§Ù…Ù‡ Ø¯Ø§Ø¯Ú¯Ø§Ù‡ - Ù†Ù…ÙˆÙ†Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡",
                    "content": """Ø¯Ø§Ø¯Ù†Ø§Ù…Ù‡ Ø´Ù…Ø§Ø±Ù‡ Û±Û´Û°Û²Û°Û¹Û¸Û·Û¶ÛµÛ´Û³Û²Û±
                    
Ø¯Ø§Ø¯Ú¯Ø§Ù‡ Ø¹Ù…ÙˆÙ…ÛŒ Ø­Ù‚ÙˆÙ‚ÛŒ ØªÙ‡Ø±Ø§Ù† - Ø´Ø¹Ø¨Ù‡ Û±Ûµ
Ù‚Ø§Ø¶ÛŒ: Ø¬Ù†Ø§Ø¨ Ø¢Ù‚Ø§ÛŒ Ø¯Ú©ØªØ± Ø­Ø³Ù† Ù…Ø­Ù…Ø¯ÛŒ

Ø¯Ø± Ø®ØµÙˆØµ Ø¯Ø¹ÙˆØ§ÛŒ Ø®Ø§Ù†Ù… Ù…Ø±ÛŒÙ… Ø§Ø­Ù…Ø¯ÛŒ Ø¹Ù„ÛŒÙ‡ Ø¢Ù‚Ø§ÛŒ Ø¹Ù„ÛŒ Ø±Ø¶Ø§ÛŒÛŒ

Ø¨Ø§ Ø¹Ù†Ø§ÛŒØª Ø¨Ù‡ Ø§ÙˆØ±Ø§Ù‚ Ù¾Ø±ÙˆÙ†Ø¯Ù‡ Ùˆ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡:

Ù…ÙˆØ¶ÙˆØ¹ Ø¯Ø¹ÙˆØ§: Ù…Ø·Ø§Ù„Ø¨Ù‡ Ù…Ø¨Ù„Øº ÛµÛ°ØŒÛ°Û°Û°ØŒÛ°Û°Û° Ø±ÛŒØ§Ù„ Ø¨Ø§Ø¨Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø®Ø±ÛŒØ¯ Ùˆ ÙØ±ÙˆØ´

Ø¯Ù„Ø§Ø¦Ù„ Ùˆ Ù…Ø³ØªÙ†Ø¯Ø§Øª:
Û±. Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø®Ø±ÛŒØ¯ Ùˆ ÙØ±ÙˆØ´ Ù…ÙˆØ±Ø® Û±Û´Û°Û²/Ûµ/Û±Û°
Û². ÙÛŒØ´ ÙˆØ§Ø±ÛŒØ²ÛŒ Ø¨Ù‡ Ù…Ø¨Ù„Øº Û²Û°ØŒÛ°Û°Û°ØŒÛ°Û°Û° Ø±ÛŒØ§Ù„
Û³. Ø´Ù‡Ø§Ø¯Øª Ø´Ù‡ÙˆØ¯

Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ú¯Ø§Ù‡:
Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ØŒ Ø¯Ø§Ø¯Ú¯Ø§Ù‡ Ø¯Ø¹ÙˆØ§ÛŒ Ø®ÙˆØ§Ù‡Ø§Ù† Ø±Ø§ ÙˆØ§Ø±Ø¯ ØªØ´Ø®ÛŒØµ Ùˆ Ø­Ú©Ù… Ø¨Ù‡ Ù…Ø­Ú©ÙˆÙ…ÛŒØª Ø®ÙˆØ§Ù†Ø¯Ù‡ ØµØ§Ø¯Ø± Ù…ÛŒâ€ŒÙ†Ù…Ø§ÛŒØ¯.""",
                    "category": "Ø¯Ø§Ø¯Ù†Ø§Ù…Ù‡",
                    "subcategory": "Ø­Ù‚ÙˆÙ‚ÛŒ",
                    "legal_domain": "Ø¢ÛŒÛŒÙ† Ø¯Ø§Ø¯Ø±Ø³ÛŒ Ù…Ø¯Ù†ÛŒ",
                    "complexity": "Ù¾ÛŒØ´Ø±ÙØªÙ‡",
                    "entities": {
                        "parties": ["Ù…Ø±ÛŒÙ… Ø§Ø­Ù…Ø¯ÛŒ", "Ø¹Ù„ÛŒ Ø±Ø¶Ø§ÛŒÛŒ"],
                        "judge": ["Ø­Ø³Ù† Ù…Ø­Ù…Ø¯ÛŒ"],
                        "amounts": ["ÛµÛ°ØŒÛ°Û°Û°ØŒÛ°Û°Û° Ø±ÛŒØ§Ù„", "Û²Û°ØŒÛ°Û°Û°ØŒÛ°Û°Û° Ø±ÛŒØ§Ù„"],
                        "case_number": ["Û±Û´Û°Û²Û°Û¹Û¸Û·Û¶ÛµÛ´Û³Û²Û±"],
                        "court": ["Ø¯Ø§Ø¯Ú¯Ø§Ù‡ Ø¹Ù…ÙˆÙ…ÛŒ Ø­Ù‚ÙˆÙ‚ÛŒ ØªÙ‡Ø±Ø§Ù† - Ø´Ø¹Ø¨Ù‡ Û±Ûµ"]
                    }
                }
            ],
            "metadata": {
                "version": "enhanced_mock_1.0",
                "created_at": time.time(),
                "enhancement_level": "detailed_entities_with_mock",
                "language": "persian",
                "is_mock_data": True
            }
        }
        
        try:
            with open(enhanced_docs_file, "w", encoding="utf-8") as f:
                json.dump(enhanced_documents, f, ensure_ascii=False, indent=2)
            
            print("âœ… Enhanced sample data created")
            return True
            
        except Exception as e:
            print(f"âŒ Failed to create enhanced data: {e}")
            return False
    
    def run_mock_enhancement(self) -> bool:
        """Run mock enhancement for testing purposes"""
        print("ğŸš€ RUNNING MOCK SYSTEM ENHANCEMENT (Testing Mode)")
        print("=" * 55)
        
        # Check existing setup first
        existing_status = self.check_existing_setup()
        
        success_count = 0
        total_steps = 4
        
        # Step 1: Mock Dependencies
        print(f"\nğŸ“¦ Step 1/{total_steps}: Mock dependencies check...")
        if self.mock_install_dependencies():
            success_count += 1
        
        # Step 2: Mock Persian BERT
        print(f"\nğŸ“¥ Step 2/{total_steps}: Mock Persian BERT creation...")
        if self.create_mock_persian_bert():
            success_count += 1
        
        # Step 3: Enhanced sample data
        print(f"\nğŸ“„ Step 3/{total_steps}: Enhanced sample data...")
        if self.create_enhanced_sample_data():
            success_count += 1
        
        # Step 4: Integration check
        print(f"\nğŸ”§ Step 4/{total_steps}: Mock integration verification...")
        integration_success = self.verify_mock_integration()
        if integration_success:
            success_count += 1
        
        success_rate = success_count / total_steps
        print(f"\nğŸ“Š MOCK ENHANCEMENT RESULTS: {success_count}/{total_steps} ({success_rate:.1%})")
        
        if success_rate >= 0.75:
            print("âœ… Mock system enhancement successful!")
            print(f"ğŸ“ Mock enhanced models: {self.enhanced_dir}")
            print("ğŸ”„ Existing functionality preserved")
            print("ğŸ­ Running in MOCK MODE for testing")
            return True
        else:
            print("âš ï¸ Mock enhancement partially successful")
            return False
    
    def verify_mock_integration(self) -> bool:
        """Verify mock enhancement integration"""
        try:
            # Check mock model
            bert_path = self.enhanced_dir / "persian_bert"
            if bert_path.exists():
                print("âœ… Mock Persian BERT structure available")
                
                # Check model info
                info_file = self.enhanced_dir / "model_info.json"
                if info_file.exists():
                    with open(info_file) as f:
                        info = json.load(f)
                    print(f"âœ… Mock model info verified: {info.get('vocab_size', 'unknown')} vocab size")
                    print(f"ğŸ­ Mock mode: {info.get('is_mock', False)}")
                
                # Check config files
                config_file = bert_path / "config.json"
                if config_file.exists():
                    print("âœ… Mock config.json available")
                
                vocab_file = bert_path / "vocab.txt"
                if vocab_file.exists():
                    print("âœ… Mock vocab.txt available")
                
                return True
            else:
                print("âŒ Mock model not found")
                return False
                
        except Exception as e:
            print(f"âŒ Mock integration verification failed: {e}")
            return False

def main():
    """Main mock enhancement function"""
    try:
        enhancer = MockEnhancedModelSetup()
        success = enhancer.run_mock_enhancement()
        
        if success:
            print("\nğŸ‰ MOCK ENHANCEMENT COMPLETED!")
            print("âœ… Existing system preserved")
            print("âœ… Mock functionality added for testing")
            print("ğŸ“ Check ai_models/enhanced/ for mock components")
            print("ğŸ­ Ready for integration testing with mock data")
        else:
            print("\nâš ï¸ Mock enhancement needs attention")
            print("ğŸ”„ Existing system remains unchanged")
        
        return success
        
    except Exception as e:
        print(f"âŒ Mock enhancement error: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)